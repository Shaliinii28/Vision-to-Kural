# -*- coding: utf-8 -*-
"""Kurals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u0OrNWDLxuYtRkIpVwn3ErKdcCUB_Eji
"""

"""
STEP 1 â€” Process the Thirukkural CSV into kural_metadata.json
Colab-compatible version (logic unchanged)
"""

import sys
import json
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Optional: Mount Google Drive (uncomment if using Drive)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# from google.colab import drive
# drive.mount('/content/drive')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PATH CONFIG FOR COLAB
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path("/content")
APP_DIR = BASE_DIR / "app"

CSV_PATH = Path("/content/kurals.csv")
OUT_PATH = APP_DIR / "kural_metadata.json"

APP_DIR.mkdir(parents=True, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Simple logger replacement (since utils not present)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import logging
logging.basicConfig(level=logging.INFO)
log = logging.getLogger("kural")

def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)

def pal_from_translation(value: str):
    """
    Map English pal translation to canonical values.
    (Same expected behavior as original utils function.)
    """
    v = value.lower()
    if "virtue" in v:
        return "Virtue"
    if "wealth" in v:
        return "Wealth"
    if "love" in v:
        return "Love"
    return ""

try:
    import pandas as pd
except ImportError:
    !pip install pandas
    import pandas as pd


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Text cleaning (UNCHANGED)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean(value) -> str:
    if value is None:
        return ""
    s = str(value).strip()
    if s.lower() in ("nan", "none", ""):
        return ""
    return s


def build_text_for_embedding(row) -> str:
    parts = []

    kural_text = clean(row.get("kural"))
    if kural_text:
        parts.append(kural_text)

    explanation = clean(row.get("explanation"))
    if explanation:
        parts.append(explanation)

    for col in ("mk", "mv", "sp"):
        commentary = clean(row.get(col))
        if commentary and len(commentary) > 15:
            parts.append(commentary)

    return " | ".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main (LOGIC UNCHANGED)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():

    if not CSV_PATH.exists():
        sys.exit(
            f"ERROR: CSV not found at {CSV_PATH}\n"
            "Upload your kurals.csv into /content/data/ and retry."
        )

    log.info(f"Reading CSV: {CSV_PATH}")
    df = pd.read_csv(
        CSV_PATH,
        encoding="utf-8",
        comment="#",       # <-- ignore comment lines
        engine="python"    # safer parser
    )
    log.info(f"Loaded {len(df)} rows, columns: {list(df.columns)}")

    required_cols = [
        "Number", "kural", "explanation",
        "adikaram_name", "iyal_name",
        "paul_name", "paul_translation",
        "mk", "mv", "sp",
    ]

    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        sys.exit(
            f"ERROR: CSV is missing columns: {missing}\n"
            f"Found columns: {list(df.columns)}"
        )

    metadata = []
    skipped = 0

    for _, row in df.iterrows():
        kural_num = row["Number"]

        kural_tamil = clean(row.get("kural"))
        if not kural_tamil:
            log.warning(f"Row {kural_num}: empty kural text â€” skipping")
            skipped += 1
            continue

        record = {
            "number": int(kural_num),

            "kural_tamil": kural_tamil,
            "explanation": clean(row.get("explanation")),

            "chapter": clean(row.get("adikaram_name")),
            "section": clean(row.get("iyal_name")),
            "pal_name": clean(row.get("paul_name")),
            "pal": pal_from_translation(
                clean(row.get("paul_translation", ""))
            ),

            "commentary_mk": clean(row.get("mk")),
            "commentary_mv": clean(row.get("mv")),
            "commentary_sp": clean(row.get("sp")),

            "text_for_embedding": build_text_for_embedding(row),
        }

        metadata.append(record)

    if len(metadata) < 1000:
        log.warning(
            f"Only {len(metadata)} Kurals processed (expected ~1330). "
            "Check your CSV for missing rows."
        )
    else:
        log.info(f"Processed {len(metadata)} Kurals ({skipped} skipped)")

    from collections import Counter
    pal_counts = Counter(k["pal"] for k in metadata)
    log.info(f"Pal distribution: {dict(pal_counts)}")

    ensure_dir(OUT_PATH.parent)
    with open(OUT_PATH, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    log.info(f"Saved â†’ {OUT_PATH}  ({OUT_PATH.stat().st_size // 1024}KB)")

    log.info("Spot-check (first 3 Kurals):")
    for k in metadata[:3]:
        log.info(f"  #{k['number']} [{k['pal']}] {k['kural_tamil'][:40]}â€¦")


if __name__ == "__main__":
    main()

with open("/content/kurals.csv", "r", encoding="utf-8") as f:
    for i in range(5):
        print(f.readline())

!pip install -q torch transformers accelerate bitsandbytes tqdm

!pip uninstall -y bitsandbytes
!pip install -q bitsandbytes>=0.46.1 transformers accelerate

"""
STEP 2 â€” Generate Sarvam-2B embeddings for all 1,330 Kurals
Colab-ready version (logic unchanged)
"""

import json
import numpy as np
from tqdm import tqdm
from pathlib import Path
import torch
from transformers import AutoTokenizer, AutoModel
from transformers import BitsAndBytesConfig

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Config (UNCHANGED)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_ID   = "sarvamai/sarvam-2b-v0.5"
MAX_LEN    = 256
BATCH_SIZE = 8

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” CHANGE THESE PATHS IF USING DRIVE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
METADATA_PATH = Path("/content/app/kural_metadata.json")
OUTPUT_PATH   = Path("/content/kural_embeddings_raw.npy")

# Example if using Drive:
# METADATA_PATH = Path("/content/drive/MyDrive/kural_metadata.json")
# OUTPUT_PATH   = Path("/content/drive/MyDrive/kural_embeddings_raw.npy")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mean-pool embedding extractor (UNCHANGED)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@torch.no_grad()
def embed_batch(texts, tokenizer, model, device):
    inputs = tokenizer(
        texts,
        return_tensors="pt",
        max_length=MAX_LEN,
        truncation=True,
        padding=True,
    ).to(device)

    out = model(**inputs, output_hidden_states=False)
    hidden = out.last_hidden_state

    mask = inputs["attention_mask"].unsqueeze(-1).float()
    pooled = (hidden * mask).sum(dim=1) / mask.sum(dim=1)

    return pooled.cpu().float().numpy()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main (logic preserved)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():

    # Validate input
    if not METADATA_PATH.exists():
        raise FileNotFoundError(f"Missing: {METADATA_PATH}")

    with open(METADATA_PATH, encoding="utf-8") as f:
        kurals = json.load(f)

    print(f"Loaded {len(kurals)} Kurals")
    texts = [k["text_for_embedding"] for k in kurals]
    print(f"Sample text (Kural #1): {texts[0][:120]}â€¦")

    # Device selection (UNCHANGED LOGIC)
    if torch.cuda.is_available():
        device = "cuda"
        print(f"Using GPU: {torch.cuda.get_device_name(0)}")
    elif torch.backends.mps.is_available():
        device = "mps"
        print("Using Apple MPS GPU")
    else:
        device = "cpu"
        print("Running on CPU â€” this will be slow.")

    # Load model (UNCHANGED LOGIC)
    print(f"Loading {MODEL_ID}â€¦")
    print("(First run downloads ~5GB â€” subsequent runs use cache)")

    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    tokenizer.pad_token = tokenizer.eos_token

    load_kwargs = {
        "output_hidden_states": False,
    }

    if device == "cuda":
        quant_config = BitsAndBytesConfig(
            load_in_8bit=True
        )
        load_kwargs["quantization_config"] = quant_config
        load_kwargs["device_map"] = "auto"
    else:
        load_kwargs["device_map"] = device
        load_kwargs["torch_dtype"] = torch.float32

    model = AutoModel.from_pretrained(MODEL_ID, **load_kwargs)
    model.eval()
    print("Model loaded âœ“")

    # Generate embeddings
    all_embeddings = []
    num_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE

    print(f"Encoding {len(texts)} Kurals in batches of {BATCH_SIZE}â€¦")

    for i in tqdm(range(0, len(texts), BATCH_SIZE), total=num_batches):
        batch = texts[i : i + BATCH_SIZE]
        emb = embed_batch(batch, tokenizer, model, device)
        all_embeddings.append(emb)

    embeddings = np.vstack(all_embeddings)

    print(f"Embeddings shape: {embeddings.shape}")
    print(f"dtype: {embeddings.dtype}  |  min: {embeddings.min():.4f}  max: {embeddings.max():.4f}")

    if not np.isfinite(embeddings).all():
        bad = (~np.isfinite(embeddings)).sum()
        print(f"WARNING: {bad} non-finite values found.")

    np.save(OUTPUT_PATH, embeddings)
    size_mb = OUTPUT_PATH.stat().st_size / 1e6
    print(f"Saved â†’ {OUTPUT_PATH}  ({size_mb:.1f} MB)")
    print("Done âœ“")


main()

pip install -U bitsandbytes>=0.46.1

import os
os.kill(os.getpid(), 9)

!pip install -q git+https://github.com/openai/CLIP.git

"""
STEP 3 â€” Train the MLP Projection Head (cross-modal alignment layer)
Colab-ready version (logic unchanged)
"""

import json
import numpy as np
from pathlib import Path
from collections import defaultdict
import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
import clip as openai_clip

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” CHANGE THESE PATHS IF USING DRIVE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
METADATA_PATH      = Path("/content/app/kural_metadata.json")
RAW_EMBEDDINGS_PATH = Path("/content/kural_embeddings_raw.npy")
PROJECTION_PATH    = Path("/content/app/projection.pt")

# Example if using Drive:
# METADATA_PATH      = Path("/content/drive/MyDrive/kural_metadata.json")
# RAW_EMBEDDINGS_PATH = Path("/content/drive/MyDrive/kural_embeddings_raw.npy")
# PROJECTION_PATH    = Path("/content/drive/MyDrive/projection.pt")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utility: simple logger
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Log:
    @staticmethod
    def info(msg): print(f"[INFO] {msg}")
    @staticmethod
    def warning(msg): print(f"[WARN] {msg}")

log = Log()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Model definition (unchanged)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ProjectionHead(nn.Module):
    def __init__(self, in_dim: int, out_dim: int = 512, hidden_dim: int = 1024):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, out_dim),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return nn.functional.normalize(self.net(x), dim=-1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# InfoNCE loss (unchanged)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def info_nce_loss(img_emb: torch.Tensor, txt_emb: torch.Tensor, temperature: float = 0.07) -> torch.Tensor:
    logits = torch.matmul(img_emb, txt_emb.T) / temperature
    labels = torch.arange(len(img_emb), device=img_emb.device)
    loss_i2t = nn.functional.cross_entropy(logits, labels)
    loss_t2i = nn.functional.cross_entropy(logits.T, labels)
    return (loss_i2t + loss_t2i) / 2.0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Synthetic training pairs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Expanded Vision-to-Kural Scene Prompts (Sample of key sections across all 133 Chapters)
CHAPTER_SCENE_PROMPTS = {
    # --- ARATHUPPAL (VIRTUE) ---
    "à®•à®Ÿà®µà¯à®³à¯ à®µà®¾à®´à¯à®¤à¯à®¤à¯": ["a person praying in a temple", "divine light shining", "meditating on a higher power"],
    "à®µà®¾à®©à¯à®šà®¿à®±à®ªà¯à®ªà¯":     ["heavy rain falling on crops", "clouds gathering in the sky", "a flowing river"],
    "à®¨à¯€à®¤à¯à®¤à®¾à®°à¯ à®ªà¯†à®°à¯à®®à¯ˆ": ["a monk in saffron robes", "a sage sitting in silence", "renouncing worldly goods"],
    "à®…à®±à®©à¯ à®µà®²à®¿à®¯à¯à®±à¯à®¤à¯à®¤à®²à¯": ["a person doing a good deed", "virtuous behavior in public", "choosing the right path"],
    "à®‡à®²à¯à®µà®¾à®´à¯à®•à¯à®•à¯ˆ":   ["a husband and wife at home", "a family sharing a meal", "domestic harmony"],
    "à®µà®¾à®´à¯à®•à¯à®•à¯ˆà®¤à¯ à®¤à¯à®£à¯ˆà®¨à®²à®®à¯": ["a supportive wife helping her husband", "a woman managing a household", "marital partnership"],
    "à®®à®•à¯à®•à®Ÿà¯à®ªà¯‡à®±à¯":     ["a parent playing with their child", "a happy family together", "children laughing"],
    "à®…à®©à¯à®ªà¯à®Ÿà¯ˆà®®à¯ˆ":     ["a person hugging a loved one", "showing affection and care", "a couple holding hands"],
    "à®µà®¿à®°à¯à®¨à¯à®¤à¯‹à®®à¯à®ªà®²à¯":   ["welcoming guests into a home", "hosting a dinner party", "offering food to visitors"],
    "à®‡à®©à®¿à®¯à®µà¯ˆ à®•à¯‚à®±à®²à¯":  ["a person speaking kindly", "a warm smile during conversation", "gentle words of comfort"],
    "à®šà¯†à®¯à¯à®¨à¯à®¨à®©à¯à®±à®¿ à®…à®±à®¿à®¤à®²à¯": ["thanking someone who helped you", "returning a favor", "a person showing deep gratitude"],
    "à®¨à®Ÿà¯à®µà¯à®¨à®¿à®²à¯ˆà®®à¯ˆ":    ["a fair judge in court", "balancing scales", "an unbiased person making a choice"],
    "à®…à®Ÿà®•à¯à®•à®®à¯à®Ÿà¯ˆà®®à¯ˆ":   ["a person bowing humbly", "showing respect to elders", "controlling one's anger"],
    "à®’à®´à¯à®•à¯à®•à®®à¯à®Ÿà¯ˆà®®à¯ˆ":   ["a disciplined person", "following a strict code of conduct", "refined behavior"],
    "à®ªà®¿à®±à®©à®¿à®²à¯ à®µà®¿à®´à¯ˆà®¯à®¾à®®à¯ˆ": ["avoiding temptation", "staying loyal to one's spouse", "moral boundaries"],
    "à®ªà¯Šà®±à¯ˆà®¯à¯à®Ÿà¯ˆà®®à¯ˆ":    ["a person staying calm under insult", "patiently waiting", "forgiving an enemy"],
    "à®…à®´à¯à®•à¯à®•à®¾à®±à®¾à®®à¯ˆ":    ["looking at others' success without envy", "contentment with what one has"],
    "à®µà¯†à®ƒà®•à®¾à®®à¯ˆ":       ["refusing to take what belongs to others", "not being greedy", "honesty in dealings"],
    "à®ªà¯à®±à®™à¯à®•à¯‚à®±à®¾à®®à¯ˆ":    ["refusing to gossip", "speaking well of others behind their back", "silence in rumors"],
    "à®ªà®¯à®©à®¿à®² à®šà¯Šà®²à¯à®²à®¾à®®à¯ˆ": ["avoiding useless talk", "speaking only what is necessary", "meaningful conversation"],
    "à®¤à¯€à®µà®¿à®©à¯ˆà®¯à®šà¯à®šà®®à¯":   ["fear of doing something wrong", "a person hesitating to commit a crime"],
    "à®’à®ªà¯à®ªà¯à®°à®µà®±à®¿à®¤à®²à¯":   ["helping the community", "a philanthropist giving back", "social duty"],
    "à®ˆà®•à¯ˆ":           ["giving money to a beggar", "donating clothes", "generosity to the poor"],
    "à®ªà¯à®•à®´à¯":          ["a person being honored", "legacy and fame", "a statue of a great leader"],
    "à®…à®°à¯à®³à¯à®Ÿà¯ˆà®®à¯ˆ":     ["showing compassion to animals", "mercy to the weak", "a kind-hearted person"],
    "à®ªà¯à®²à®¾à®²à¯ à®®à®±à¯à®¤à¯à®¤à®²à¯": ["vegetarian food", "refusing to eat meat", "kindness to living beings"],
    "à®¤à®µà®®à¯":           ["an ascetic meditating in the woods", "extreme self-discipline", "spiritual heat"],
    "à®•à¯‚à®Ÿà®¾à®µà¯Šà®´à¯à®•à¯à®•à®®à¯":   ["a hypocrite hiding their face", "false saintliness", "deceptive behavior"],
    "à®•à®³à¯à®³à®¾à®®à¯ˆ":       ["not stealing", "integrity in small things", "returning a lost wallet"],
    "à®µà®¾à®¯à¯à®®à¯ˆ":         ["a person telling the truth", "honest conversation", "swearing an oath"],
    "à®µà¯†à®•à¯à®³à®¾à®®à¯ˆ":       ["calming down from anger", "peaceful reaction to stress", "inner peace"],
    "à®‡à®©à¯à®©à®¾ à®šà¯†à®¯à¯à®¯à®¾à®®à¯ˆ": ["refusing to hurt someone who hurt you", "non-violence", "Ahimsa"],
    "à®•à¯Šà®²à¯à®²à®¾à®®à¯ˆ":       ["saving an insect's life", "not killing", "protection of all life"],
    "à®¨à®¿à®²à¯ˆà®¯à®¾à®®à¯ˆ":       ["a sunset representing the end", "falling leaves", "impermanence of life"],
    "à®¤à¯à®±à®µà¯":           ["breaking chains", "letting go of attachments", "freedom from desire"],
    "à®®à¯†à®¯à¯à®ªà¯à®ªà¯à®£à®°à¯à®¤à®²à¯":   ["realizing the truth", "clarity of mind", "enlightenment"],
    "à®…à®µà®¾à®µà®±à¯à®¤à¯à®¤à®²à¯":     ["killing desire", "peace through minimalism", "no cravings"],
    "à®Šà®´à¯":             ["destiny and fate", "the turning wheel of time", "inevitable outcomes"],

    # --- PORUTPAL (WEALTH / POLITICS) ---
    "à®‡à®±à¯ˆà®®à®¾à®Ÿà¯à®šà®¿":      ["a majestic king", "a great leader standing tall", "authority and grace"],
    "à®•à®²à¯à®µà®¿":           ["a student studying hard", "books and learning", "a library setting"],
    "à®•à®²à¯à®²à®¾à®®à¯ˆ":       ["an uneducated person", "the darkness of ignorance", "refusing to learn"],
    "à®•à¯‡à®³à¯à®µà®¿":         ["listening to an elder", "attending a lecture", "learning by hearing"],
    "à®…à®±à®¿à®µà¯à®Ÿà¯ˆà®®à¯ˆ":     ["a scholar reading", "wise decision making", "intellectual depth"],
    "à®•à¯à®±à¯à®±à®™à¯à®•à®Ÿà®¿à®¤à®²à¯":   ["self-correction", "fixing one's own mistakes", "removing flaws"],
    "à®ªà¯†à®°à®¿à®¯à®¾à®°à¯ˆà®¤à¯ à®¤à¯à®£à¯ˆà®•à¯à®•à¯‹à®Ÿà®²à¯": ["seeking advice from a mentor", "walking with wise elders"],
    "à®šà®¿à®±à¯à®±à®¿à®©à®®à¯ à®šà¯‡à®°à®¾à®®à¯ˆ": ["avoiding bad company", "choosing good friends", "social boundaries"],
    "à®¤à¯†à®°à®¿à®¨à¯à®¤à¯à®šà¯†à®¯à®²à¯à®µà®•à¯ˆ": ["careful planning", "thinking before acting", "strategy board"],
    "à®¤à¯†à®°à®¿à®¨à¯à®¤à¯ à®¤à¯†à®³à®¿à®¤à®²à¯": ["hiring the right person", "checking credentials", "trusting the worthy"],
    "à®¤à¯†à®°à®¿à®¨à¯à®¤à¯ à®µà®¿à®©à¯ˆà®¯à®¾à®Ÿà®²à¯": ["assigning tasks to experts", "delegation of work", "management"],
    "à®šà¯à®±à¯à®±à®¨à¯à®¤à®´à®¾à®²à¯":     ["a reunion of relatives", "embracing family members", "kinship"],
    "à®ªà¯Šà®šà¯à®šà®¾à®µà®¾à®®à¯ˆ":     ["being alert", "avoiding forgetfulness", "sharp focus"],
    "à®šà¯†à®™à¯à®•à¯‹à®©à¯à®®à¯ˆ":      ["a fair scepter", "just governance", "a king listening to citizens"],
    "à®•à¯Šà®Ÿà¯à®™à¯à®•à¯‹à®©à¯à®®à¯ˆ":    ["a tyrant king", "oppression of people", "cruel leadership"],
    "à®µà¯†à®°à¯à®µà®¨à¯à®¤ à®šà¯†à®¯à¯à®¯à®¾à®®à¯ˆ": ["not scaring subordinates", "gentle authority", "approachable leader"],
    "à®•à®£à¯à®£à¯‹à®Ÿà¯à®Ÿà®®à¯":      ["looking with kindness", "consideration for others", "sympathetic gaze"],
    "à®’à®±à¯à®±à®¾à®Ÿà®²à¯":         ["a spy gathering information", "surveillance", "secret intelligence"],
    "à®Šà®•à¯à®•à®®à¯à®Ÿà¯ˆà®®à¯ˆ":     ["inner drive", "high energy for work", "unshakable enthusiasm"],
    "à®®à®Ÿà®¿à®¯à®¿à®©à¯à®®à¯ˆ":       ["not being lazy", "getting up early", "active lifestyle"],
    "à®†à®³à¯à®µà®¿à®©à¯ˆà®¯à¯à®Ÿà¯ˆà®®à¯ˆ":   ["persistent effort", "a person working hard despite failure", "tenacity"],
    "à®‡à®Ÿà¯à®•à¯à®•à®£à¯ à®…à®´à®¿à®¯à®¾à®®à¯ˆ": ["smiling in the face of trouble", "courage in crisis", "not being depressed"],
    "à®…à®®à¯ˆà®šà¯à®šà¯":         ["a minister advising", "political consultation", "statesmanship"],
    "à®šà¯Šà®²à¯à®µà®©à¯à®®à¯ˆ":      ["eloquent speech", "powerful oratory", "persuasive talking"],
    "à®µà®¿à®©à¯ˆà®¤à¯à®¤à¯‚à®¯à¯à®®à¯ˆ":     ["pure methods of working", "ethical business", "clean hands"],
    "à®µà®¿à®©à¯ˆà®¤à¯à®¤à®¿à®Ÿà¯à®ªà®®à¯":     ["firmness in action", "resolute execution", "not giving up halfway"],
    "à®µà®¿à®©à¯ˆà®šà¯†à®¯à®²à¯à®µà®•à¯ˆ":    ["different ways to finish a job", "efficient workflow", "tactics"],
    "à®¤à¯‚à®¤à¯":           ["a diplomat traveling", "an ambassador speaking", "messengers"],
    "à®®à®©à¯à®©à®°à¯ˆà®šà¯ à®šà¯‡à®°à¯à®¨à¯à®¤à¯Šà®´à¯à®¤à®²à¯": ["behaving in front of leaders", "royal etiquette", "palace manners"],
    "à®•à¯à®±à®¿à®ªà¯à®ªà®±à®¿à®¤à®²à¯":      ["reading body language", "understanding unspoken words", "intuition"],
    "à®…à®µà¯ˆ à®…à®±à®¿à®¤à®²à¯":      ["understanding the audience", "speaking appropriately in public"],
    "à®…à®µà¯ˆ à®…à®à¯à®šà®¾à®®à¯ˆ":     ["public speaking confidence", "not being afraid of a crowd"],
    "à®¨à®¾à®Ÿà¯":            ["a prosperous country", "fertile lands", "peaceful nation"],
    "à®…à®°à®£à¯":           ["a strong fortress", "defensive walls", "security and protection"],
    "à®ªà¯Šà®°à¯à®³à¯à®šà¯†à®¯à®²à¯à®µà®•à¯ˆ":  ["earning money honestly", "wealth accumulation", "investment"],
    "à®ªà®Ÿà¯ˆà®®à®¾à®Ÿà¯à®šà®¿":       ["a brave army", "disciplined soldiers", "military strength"],
    "à®ªà®Ÿà¯ˆà®šà¯à®šà¯†à®°à¯à®•à¯à®•à¯":     ["heroic pride", "valiant warriors in battle", "courage of a soldier"],
    "à®¨à®Ÿà¯à®ªà¯":           ["two friends laughing together", "loyalty and trust", "mutual support"],
    "à®¨à®Ÿà¯à®ªà®¾à®°à®¾à®¯à¯à®¤à®²à¯":      ["testing a friendship", "choosing friends carefully", "scrutiny"],
    "à®ªà®´à¯ˆà®®à¯ˆ":          ["long-term friendship", "comfort and familiarity", "old friends"],
    "à®¤à¯€à®¨à®Ÿà¯à®ªà¯":         ["toxic friendship", "a friend who causes harm", "fake smile"],
    "à®•à¯‚à®Ÿà®¾à®¨à®Ÿà¯à®ªà¯":       ["an enemy disguised as a friend", "betrayal", "treacherous alliance"],
    "à®ªà¯‡à®¤à¯ˆà®®à¯ˆ":         ["foolishness", "ignorant behavior", "acting without thinking"],
    "à®ªà¯à®²à¯à®²à®±à®¿à®µà®¾à®£à¯à®®à¯ˆ":    ["shallow knowledge", "vanity of the half-learned", "stubbornness"],
    "à®‡à®•à®´à¯":           ["hostility and hatred", "conflict between people", "enmity"],
    "à®ªà®•à¯ˆà®®à®¾à®Ÿà¯à®šà®¿":       ["strength of the enemy", "strategic opposition", "rivalry"],
    "à®ªà®•à¯ˆà®¤à¯à®¤à®¿à®±à®¨à¯à®¤à¯†à®°à®¿à®¤à®²à¯": ["knowing the enemy's weakness", "analyzing opposition"],
    "à®‰à®Ÿà¯à®ªà®•à¯ˆ":         ["a traitor within the group", "internal conflict", "hidden enemy"],
    "à®ªà¯†à®°à®¿à®¯à®¾à®°à¯ˆà®ªà¯ à®ªà®¿à®´à¯ˆà®¯à®¾à®®à¯ˆ": ["not offending the powerful", "respecting greatness", "avoiding hubris"],
    "à®ªà¯†à®£à¯à®µà®´à®¿à®šà¯à®šà¯‡à®±à®²à¯":    ["being overly influenced by a woman", "losing focus due to lust"],
    "à®µà®°à¯ˆà®µà®¿à®©à¯ à®®à®•à®³à®¿à®°à¯":    ["women of the street", "unfaithful relationships", "lustful trap"],
    "à®•à®³à¯à®³à¯à®£à¯à®£à®¾à®®à¯ˆ":     ["avoiding alcohol", "sobriety", "drunkenness and shame"],
    "à®šà¯‚à®¤à¯":           ["gambling with dice", "losing money in games", "addiction"],
    "à®®à®°à¯à®¨à¯à®¤à¯":         ["food as medicine", "a doctor treating a patient", "healthy eating"],
    "à®•à¯à®Ÿà®¿à®®à¯ˆ":         ["noble birth and character", "dignity and family honor"],
    "à®®à®¾à®©à®®à¯":           ["self-respect", "choosing death over dishonor", "pride"],
    "à®ªà¯†à®°à¯à®®à¯ˆ":         ["greatness of character", "humility in high position", "excellence"],
    "à®šà®¾à®©à¯à®±à®¾à®£à¯à®®à¯ˆ":      ["perfect character", "a pillar of society", "balance of virtues"],
    "à®ªà®£à¯à®ªà¯à®Ÿà¯ˆà®®à¯ˆ":       ["good manners", "being cultured and polite", "social grace"],
    "à®¨à®©à¯à®±à®¿à®¯à®¿à®²à¯ à®šà¯†à®²à¯à®µà®®à¯": ["useless wealth", "a miser hoarding money", "rich but unhappy"],
    "à®¨à®¾à®£à¯à®Ÿà¯ˆà®®à¯ˆ":       ["shame in doing wrong", "modesty", "moral sensitivity"],
    "à®•à¯à®Ÿà®¿à®šà¯†à®¯à®²à¯à®µà®•à¯ˆ":     ["uplifting one's family", "hard work for the lineage", "dedication"],
    "à®‰à®´à®µà¯":           ["a farmer plowing", "agriculture", "foundation of the economy"],
    "à®¨à®²à¯à®•à¯à®°à®µà¯":         ["poverty", "a person struggling for food", "economic hardship"],
    "à®‡à®°à®µà¯":           ["begging for help", "asking for charity", "dependency"],
    "à®‡à®°à®µà®šà¯à®šà®®à¯":        ["dignity of not begging", "self-sufficiency", "hating dependency"],
    "à®•à®¯à®®à¯ˆ":           ["lowly behavior", "mean-spirited people", "wickedness"],

    # --- KAMATHUPPAL (LOVE) ---
    "à®¤à®•à¯ˆà®£à®™à¯à®•à®£à¯à®±à¯à®¤à¯à®¤à®²à¯": ["falling in love at first sight", "beauty of the beloved"],
    "à®•à¯à®±à®¿à®ªà¯à®ªà®±à®¿à®¤à®²à¯(K)":  ["understanding signs of love", "glances between lovers"],
    "à®ªà¯à®£à®°à¯à®šà¯à®šà®¿ à®®à®•à®¿à®´à¯à®¤à®²à¯": ["joy of union", "lovers embracing", "happiness together"],
    "à®¨à®²à®®à¯ à®ªà¯à®©à¯ˆà®¨à¯à®¤à¯à®°à¯ˆà®¤à¯à®¤à®²à¯": ["praising the beauty of the lover", "romantic poetry"],
    "à®•à®¾à®¤à®±à¯ à®šà®¿à®±à®ªà¯à®ªà¯à®°à¯ˆà®¤à¯à®¤à®²à¯": ["the uniqueness of their love", "deep soul connection"],
    "à®¨à®¾à®£à¯à®¤à¯ à®¤à¯à®±à®µà¯à®°à¯ˆà®¤à¯à®¤à®²à¯": ["losing modesty in love", "expressive passion"],
    "à®…à®²à®°à®±à®¿à®µà¯à®±à¯à®¤à¯à®¤à®²à¯":    ["neighborhood gossip about lovers", "rumors in the village"],
    "à®ªà®¿à®°à®¿à®µà®¾à®±à¯à®±à®¾à®®à¯ˆ":     ["pain of separation", "longing for the absent lover", "sadness"],
    "à®ªà®Ÿà®°à¯à®®à¯†à®²à®¿à®¨à¯à®¤à®¿à®°à®™à¯à®•à®²à¯": ["pining away", "becoming thin from grief", "fading health due to love"],
    "à®•à®£à¯à®µà®¿à®¤à¯à®ªà¯à®ªà®´à®¿à®¤à®²à¯":   ["eyes weeping for the lover", "looking at the path for their return"],
    "à®ªà®šà®ªà¯à®ªà¯à®±à¯ à®ªà®°à¯à®µà®°à®²à¯":   ["the pallor of separation", "skin changing color due to grief"],
    "à®¤à®©à®¿à®ªà¯à®ªà®Ÿà®°à¯ à®®à®¿à®•à¯à®¤à®¿":    ["the intensity of loneliness", "suffering alone in the dark"],
    "à®¨à®¿à®©à¯ˆà®¨à¯à®¤à®µà®°à¯ à®ªà¯à®²à®®à¯à®ªà®²à¯": ["reminiscing about past moments", "talking to memories"],
    "à®•à®©à®µà¯ à®¨à®¿à®²à¯ˆ à®‰à®°à¯ˆà®¤à¯à®¤à®²à¯": ["seeing the lover in a dream", "waking up to find them gone"],
    "à®ªà¯Šà®´à¯à®¤à¯à®•à®£à¯à®Ÿà¯ à®‡à®°à®™à¯à®•à®²à¯": ["sadness at sunset", "evening bringing more pain"],
    "à®‰à®±à¯à®ªà¯à®ªà¯à®¨à®²à®©à¯ à®…à®´à®¿à®¤à®²à¯": ["fading beauty due to separation", "weary limbs"],
    "à®¨à¯†à®à¯à®šà¯Šà®Ÿà¯ à®•à®¿à®³à®¤à¯à®¤à®²à¯": ["talking to one's own heart", "internal romantic monologue"],
    "à®¨à®¿à®±à¯ˆà®¯à®´à®¿à®¤à®²à¯":       ["losing self-control in love", "flooding emotions"],
    "à®…à®µà®°à¯à®µà®¯à®¿à®©à¯ à®µà®¿à®¤à¯à®®à¯à®ªà®²à¯": ["desperate desire to meet", "impatience in love"],
    "à®•à¯à®±à®¿à®ªà¯à®ªà®±à®¿à®µà¯à®±à¯à®¤à¯à®¤à®²à¯(P)": ["subtle hints between lovers", "silent communication"],
    "à®ªà¯à®£à®°à¯à®šà¯à®šà®¿ à®µà®¿à®¤à¯à®ªà¯à®ªà®²à¯": ["eagerness for the embrace", "passionate reunion"],
    "à®¨à¯†à®à¯à®šà¯Šà®Ÿà¯ à®ªà¯à®²à®¤à¯à®¤à®²à¯": ["arguing with one's own heart", "conflicting feelings"],
    "à®ªà¯à®²à®µà®¿":           ["a lover's tiff", "small misunderstanding", "pouting"],
    "à®ªà¯à®²à®µà®¿ à®¨à¯à®£à¯à®•à¯à®•à®®à¯":   ["subtle feigned anger", "testing the lover's affection"],
    "à®Šà®Ÿà®²à¯à®µà®•à¯ˆ":       ["the joy of making up after a fight", "reconciliation"],
}

GENERIC_PROMPTS = [
    "a person helping a stranger",
    "people working together as a team",
    "someone making a difficult decision",
    "a peaceful scene in nature",
    "an act of kindness",
    "a person reflecting and thinking",
    "community and togetherness",
    "an elder sharing wisdom",
]

def build_training_pairs(kurals, kural_embeddings, clip_model, device):
    from torch import nn
    from collections import defaultdict
    log.info("Building synthetic training pairsâ€¦")

    chapter_to_indices = defaultdict(list)
    for i, k in enumerate(kurals):
        chapter_to_indices[k["chapter"]].append(i)

    pairs_img = []
    pairs_txt = []

    for chapter, indices in chapter_to_indices.items():
        matching_prompts = []
        for kw, prompts in CHAPTER_SCENE_PROMPTS.items():
            if kw in chapter or chapter in kw:
                matching_prompts.extend(prompts)
        if not matching_prompts:
            matching_prompts = GENERIC_PROMPTS[:3]

        with torch.no_grad():
            tokens = openai_clip.tokenize(matching_prompts[:5]).to(device)
            clip_text_feats = clip_model.encode_text(tokens).float()
            clip_text_feats = nn.functional.normalize(clip_text_feats, dim=-1)

        for clip_feat in clip_text_feats:
            for idx in indices:
                sarvam_feat = torch.tensor(kural_embeddings[idx], dtype=torch.float32)
                pairs_img.append(clip_feat.cpu())
                pairs_txt.append(sarvam_feat)

    with torch.no_grad():
        tokens = openai_clip.tokenize(GENERIC_PROMPTS).to(device)
        generic_feats = clip_model.encode_text(tokens).float()
        generic_feats = nn.functional.normalize(generic_feats, dim=-1)

    rng = np.random.default_rng(42)
    for clip_feat in generic_feats:
        for idx in rng.choice(len(kurals), size=10, replace=False):
            pairs_img.append(clip_feat.cpu())
            pairs_txt.append(torch.tensor(kural_embeddings[idx], dtype=torch.float32))

    log.info(f"Built {len(pairs_img)} training pairs from {len(chapter_to_indices)} chapters")
    return pairs_img, pairs_txt

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main training loop
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(epochs=200, lr=3e-4, batch_size=64):
    assert METADATA_PATH.exists(), f"Missing: {METADATA_PATH}"
    assert RAW_EMBEDDINGS_PATH.exists(), f"Missing: {RAW_EMBEDDINGS_PATH}"

    with open(METADATA_PATH, encoding="utf-8") as f:
        kurals = json.load(f)

    kural_embeddings = np.load(RAW_EMBEDDINGS_PATH)
    log.info(f"Loaded {len(kurals)} kurals, embeddings shape: {kural_embeddings.shape}")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    log.info(f"Training on: {device}")

    log.info("Loading CLIP ViT-L/14â€¦")
    clip_model, _ = openai_clip.load("ViT-L/14", device=device)
    clip_model.eval()
    log.info("CLIP loaded âœ“")

    pairs_img, pairs_txt = build_training_pairs(kurals, kural_embeddings, clip_model, device)
    n_pairs = len(pairs_img)
    log.info(f"Total training pairs: {n_pairs}")

    img_feats = torch.stack(pairs_img).to(device)
    txt_feats = torch.stack(pairs_txt).to(device)

    img_proj = ProjectionHead(in_dim=768, out_dim=512).to(device)
    text_proj = ProjectionHead(in_dim=2048, out_dim=512).to(device)

    params = list(img_proj.parameters()) + list(text_proj.parameters())
    optimizer = AdamW(params, lr=lr, weight_decay=1e-2)
    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-5)

    log.info(f"Training for {epochs} epochsâ€¦")
    losses = []

    img_proj.train()
    text_proj.train()

    for epoch in range(1, epochs + 1):
        perm = torch.randperm(n_pairs, device=device)
        epoch_losses = []

        for i in range(0, n_pairs, batch_size):
            idx = perm[i : i + batch_size]
            if len(idx) < 2:
                continue

            img_batch = img_feats[idx]
            txt_batch = txt_feats[idx]

            img_emb = img_proj(img_batch)
            txt_emb = text_proj(txt_batch)

            loss = info_nce_loss(img_emb, txt_emb)

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)
            optimizer.step()

            epoch_losses.append(loss.item())

        scheduler.step()
        mean_loss = sum(epoch_losses) / len(epoch_losses)
        losses.append(mean_loss)

        if epoch % 10 == 0 or epoch == 1:
            log.info(f"Epoch {epoch:3d}/{epochs}  |  loss: {mean_loss:.4f}  |  lr: {scheduler.get_last_lr()[0]:.2e}")

    # Save weights
    PROJECTION_PATH.parent.mkdir(parents=True, exist_ok=True)
    torch.save({
        "img_proj":  img_proj.state_dict(),
        "text_proj": text_proj.state_dict(),
        "config": {
            "img_in_dim":  768,
            "txt_in_dim":  2048,
            "out_dim":     512,
            "hidden_dim":  1024,
        }
    }, PROJECTION_PATH)
    log.info(f"Saved â†’ {PROJECTION_PATH} ({PROJECTION_PATH.stat().st_size / 1e6:.1f} MB)")

    # Save loss curve
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(8, 4))
        plt.plot(range(1, epochs + 1), losses, color="#1A56A8", linewidth=2)
        plt.xlabel("Epoch"); plt.ylabel("InfoNCE Loss")
        plt.title("Projection Head Training Loss")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plot_path = PROJECTION_PATH.parent / "training_loss.png"
        plt.savefig(plot_path, dpi=150)
        log.info(f"Loss curve saved â†’ {plot_path}")
    except Exception as e:
        log.warning(f"Could not save loss plot: {e}")

    log.info(f"Final loss: {losses[-1]:.4f}")
    log.info("Next step: python scripts/04_build_faiss.py")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Colab-friendly entry
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # Direct call in Colab without argparse
    main(epochs=200, lr=3e-4, batch_size=64)

"""
STEP 4 â€” Build the FAISS vector index (Colab-ready)
==================================================

Input:
  - /content/app/kural_embeddings_raw.npy  (Step 2)
  - /content/app/projection.pt             (Step 3)
  - /content/app/kural_metadata.json       (Step 1)

Output:
  - /content/app/kural_index.faiss
  - /content/app/kural_embeddings_projected.npy
"""

import sys
import json
import numpy as np
from pathlib import Path

try:
    import torch
    import torch.nn as nn
    import faiss
except ImportError:
    !pip install faiss-cpu torch
    import torch
    import torch.nn as nn
    import faiss

APP_DIR = Path("/content/app")
RAW_EMB = Path("/content/kural_embeddings_raw.npy")      # <-- fix here
PROJ_PT  = APP_DIR / "projection.pt"
META_JSON= APP_DIR / "kural_metadata.json"
FAISS_IDX= APP_DIR / "kural_index.faiss"
PROJ_NPY = APP_DIR / "kural_embeddings_projected.npy"

# â”€â”€ Logger replacement â”€â”€
def log_info(msg): print(f"[INFO] {msg}")
def log_warning(msg): print(f"[WARNING] {msg}")
def log_error(msg): print(f"[ERROR] {msg}")

def check_file(path: Path, name: str):
    if not path.exists():
        log_error(f"Missing file: {name} â†’ {path}")
        sys.exit(1)

# â”€â”€ Reuse same ProjectionHead architecture â”€â”€
class ProjectionHead(nn.Module):
    def __init__(self, in_dim: int, out_dim: int = 512, hidden_dim: int = 1024):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, out_dim),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return nn.functional.normalize(self.net(x), dim=-1)

# â”€â”€ Main â”€â”€
def main():
    check_file(RAW_EMB, "kural_embeddings_raw.npy (Step 2)")
    check_file(PROJ_PT, "projection.pt (Step 3)")
    check_file(META_JSON, "kural_metadata.json (Step 1)")

    # Load raw embeddings
    raw = np.load(RAW_EMB).astype(np.float32)  # (1330, 2048)
    log_info(f"Loaded raw embeddings: {raw.shape}")

    # Load trained projection head
    ckpt = torch.load(PROJ_PT, map_location="cpu")
    cfg = ckpt.get("config", {})
    txt_in_dim = cfg.get("txt_in_dim", 2048)
    out_dim    = cfg.get("out_dim", 512)
    hidden_dim = cfg.get("hidden_dim", 1024)

    text_proj = ProjectionHead(in_dim=txt_in_dim, out_dim=out_dim, hidden_dim=hidden_dim)
    text_proj.load_state_dict(ckpt["text_proj"])
    text_proj.eval()
    log_info(f"Loaded text projector: {txt_in_dim} â†’ {out_dim}")

    # Project embeddings
    with torch.no_grad():
        tensor = torch.tensor(raw)
        projected = text_proj(tensor).numpy()  # (1330, 512)

    log_info(f"Projected embeddings: {projected.shape}")

    # L2-normalise for cosine similarity
    faiss.normalize_L2(projected)

    # Verify no NaN/Inf
    if not np.isfinite(projected).all():
        bad = (~np.isfinite(projected)).sum()
        log_error(f"{bad} non-finite values after projection")
        sys.exit(1)

    # Build FAISS index
    dimension = projected.shape[1]  # 512
    index = faiss.IndexFlatIP(dimension)
    index.add(projected)
    log_info(f"FAISS index: {index.ntotal} vectors, dimension {dimension}")

    # Sanity check
    query = projected[0:1].copy()
    scores, indices = index.search(query, k=5)
    log_info(f"Sanity check: top-5 neighbours of Kural #0: indices={indices[0]}, scores={scores[0].round(3)}")
    if indices[0][0] != 0:
        log_warning("Top-1 result is not self â€” this is unusual but may be OK.")

    # Save index and projected embeddings
    faiss.write_index(index, str(FAISS_IDX))
    size_kb = FAISS_IDX.stat().st_size // 1024
    log_info(f"Saved â†’ {FAISS_IDX} ({size_kb} KB)")

    np.save(PROJ_NPY, projected)
    log_info(f"Saved projected embeddings â†’ {PROJ_NPY}")

    # Quick retrieval tests
    with open(META_JSON, encoding="utf-8") as f:
        kurals = json.load(f)

    log_info("Quick retrieval tests:")
    for test_idx in [0, 62, 296, 1294]:
        if test_idx < len(kurals):
            q = projected[test_idx:test_idx+1].copy()
            _, top = index.search(q, k=3)
            names = [f"#{kurals[i]['number']}" for i in top[0]]
            log_info(f"  Kural #{kurals[test_idx]['number']} â†’ top-3: {', '.join(names)}")

    log_info("FAISS index ready for retrieval!")

if __name__ == "__main__":
    main()

# â”€â”€ Step 5: Evaluate retrieval quality (Colab-ready) â”€â”€
import sys
import json
from pathlib import Path
from collections import defaultdict

import torch
import torch.nn as nn
import faiss
import clip as openai_clip
from PIL import Image

# â”€â”€ Colab paths â”€â”€
APP_DIR    = Path("/content/app")
FAISS_IDX  = APP_DIR / "kural_index.faiss"
PROJ_PT    = APP_DIR / "projection.pt"
META_JSON  = APP_DIR / "kural_metadata.json"

# â”€â”€ Logging â”€â”€
class log:
    @staticmethod
    def info(msg): print(f"[INFO] {msg}")
    @staticmethod
    def warning(msg): print(f"[WARNING] {msg}")
    @staticmethod
    def error(msg): print(f"[ERROR] {msg}")

def check_file(path: Path, name: str):
    if not path.exists():
        log.error(f"Missing file: {name} â†’ {path}")
        sys.exit(1)

# â”€â”€ Projection Head â”€â”€
class ProjectionHead(nn.Module):
    def __init__(self, in_dim, out_dim=512, hidden_dim=1024):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, out_dim),
        )
    def forward(self, x):
        return nn.functional.normalize(self.net(x), dim=-1)

# â”€â”€ Test cases â”€â”€
TEST_CASES = [
    ("a parent lovingly watching their child play",          "Virtue", "à®®à®•à¯à®•à®Ÿà¯"),
    ("two friends laughing and helping each other",          "Virtue", "à®¨à®Ÿà¯à®ªà¯"),
    ("a person telling the truth to a judge",                "Virtue", "à®µà®¾à®¯à¯à®®à¯ˆ"),
    ("a disciplined person studying books diligently",       "Virtue", "à®•à®²à¯à®µà®¿"),
    ("a ruler making fair judgements for the people",        "Wealth", "à®¨à®²à¯à®²à®¾à®Ÿà¯"),
    ("a hardworking farmer tilling the fields",              "Wealth", "à®µà¯‡à®³à®¾à®£à¯"),
    ("two people in love gazing at each other",              "Love",   "à®•à®¾à®®à®®à¯"),
    ("a person crying alone missing their loved one",        "Love",   "à®ªà®¿à®°à®¿à®µà¯"),
    ("sharing a meal with guests at home",                   "Virtue", "à®µà®¿à®°à¯à®¨à¯à®¤à¯"),
    ("a person meditating and renouncing worldly desires",   "Virtue", "à®¤à¯à®±à®µà¯"),
    ("a king rewarding a loyal minister",                    "Wealth", "à®…à®®à¯ˆà®šà¯"),
    ("a woman longing for her absent husband",               "Love",   "à®ªà¯†à®£à¯"),
    ("a person who never gives up despite hardship",         "Virtue", "à®®à®Ÿà®¿"),
    ("gratitude shown to someone who helped in need",        "Virtue", "à®šà¯†à®¯à¯à®¨à®©à¯à®±à®¿"),
    ("speaking kind and gentle words to others",             "Virtue", "à®‡à®©à¯à®šà¯Šà®²à¯"),
]

# â”€â”€ Metrics computation â”€â”€
def compute_metrics(results):
    pal_hit_k = {1:0, 3:0, 5:0}
    chapter_hit_k = {1:0, 3:0, 5:0}
    for r in results:
        expected_pal = r["expected_pal"]
        expected_kw  = r["expected_chapter_kw"]
        retrieved    = r["retrieved"]
        for k in [1,3,5]:
            top_k = retrieved[:k]
            pals    = [x["pal"] for x in top_k]
            chapters= [x["chapter"] for x in top_k]
            if expected_pal in pals:
                pal_hit_k[k] += 1
            if any(expected_kw in ch for ch in chapters):
                chapter_hit_k[k] += 1
    n = len(results)
    return {
        "n_queries": n,
        "pal_hit@1": pal_hit_k[1]/n,
        "pal_hit@3": pal_hit_k[3]/n,
        "pal_hit@5": pal_hit_k[5]/n,
        "chapter_hit@1": chapter_hit_k[1]/n,
        "chapter_hit@3": chapter_hit_k[3]/n,
        "chapter_hit@5": chapter_hit_k[5]/n,
    }

# â”€â”€ Main evaluation â”€â”€
def main(image_dir: str | None = None):
    for p, name in zip([FAISS_IDX, PROJ_PT, META_JSON],
                       ["faiss_index", "projection.pt", "metadata"]):
        check_file(p, name)

    with open(META_JSON, encoding="utf-8") as f:
        kurals = json.load(f)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    log.info("Loading CLIP ViT-L/14â€¦")
    clip_model, clip_preprocess = openai_clip.load("ViT-L/14", device=device)
    clip_model.eval()

    # Load projection head
    ckpt = torch.load(PROJ_PT, map_location="cpu")
    cfg = ckpt.get("config", {})
    img_proj = ProjectionHead(in_dim=cfg.get("img_in_dim", 768), out_dim=cfg.get("out_dim", 512))
    img_proj.load_state_dict(ckpt["img_proj"])
    img_proj.eval()
    img_proj = img_proj.to(device)

    # Load FAISS index
    index = faiss.read_index(str(FAISS_IDX))
    log.info(f"FAISS index loaded: {index.ntotal} vectors")

    # â”€â”€ Retrieval functions â”€â”€
    def retrieve(query_vec: np.ndarray, k: int = 5):
        faiss.normalize_L2(query_vec)
        scores, indices = index.search(query_vec, k=k)
        results = []
        for score, idx in zip(scores[0], indices[0]):
            k_data = kurals[idx].copy()
            k_data["score"] = float(score)
            results.append(k_data)
        return results

    def encode_text(text: str):
        tokens = openai_clip.tokenize([text]).to(device)
        with torch.no_grad():
            clip_feat = clip_model.encode_text(tokens).float()
            projected = img_proj(clip_feat)
        return projected.cpu().numpy().astype("float32")

    # â”€â”€ TEXT EVALUATION â”€â”€
    log.info("="*60)
    log.info("TEXT-TO-KURAL EVALUATION")
    log.info("="*60)

    all_results = []
    for query, expected_pal, expected_kw in TEST_CASES:
        query_vec = encode_text(query)
        retrieved = retrieve(query_vec, k=5)
        result = {
            "query": query,
            "expected_pal": expected_pal,
            "expected_chapter_kw": expected_kw,
            "retrieved": retrieved,
        }
        all_results.append(result)
        print(f"\nQuery: \"{query}\"")
        print(f"Expected: {expected_pal} / chapter contains '{expected_kw}'")
        for i, r in enumerate(retrieved[:3], 1):
            match_pal = "âœ“" if r["pal"] == expected_pal else "âœ—"
            match_ch  = "âœ“" if expected_kw in r["chapter"] else " "
            print(f"  {i}. [Pal:{match_pal} Ch:{match_ch}] #{r['number']:4d} {r['chapter']:15s} "
                  f"| score={r['score']:.3f} | {r['kural_tamil'][:35]}â€¦")

    # â”€â”€ Metrics â”€â”€
    metrics = compute_metrics(all_results)
    print("\n" + "="*60)
    print("METRICS SUMMARY")
    print("="*60)
    for k,v in metrics.items():
        if k!="n_queries":
            print(f"  {k:18s}: {v:.1%}")
    print("="*60)

    # â”€â”€ IMAGE EVALUATION (optional) â”€â”€
    if image_dir:
        image_path = Path(image_dir)
        image_files = list(image_path.glob("*.jpg")) + list(image_path.glob("*.png"))
        if not image_files:
            log.warning(f"No images found in {image_dir}")
        else:
            log.info(f"\nIMAGE EVALUATION ({len(image_files)} images)")
            for img_path in image_files[:10]:
                img = Image.open(img_path).convert("RGB")
                tensor = clip_preprocess(img).unsqueeze(0).to(device)
                with torch.no_grad():
                    clip_feat = clip_model.encode_image(tensor).float()
                    projected = img_proj(clip_feat)
                query_vec = projected.cpu().numpy().astype("float32")
                retrieved = retrieve(query_vec, k=3)
                print(f"\nImage: {img_path.name}")
                for i, r in enumerate(retrieved, 1):
                    print(f"  {i}. #{r['number']:4d} [{r['pal']:7s}] {r['chapter']:20s} score={r['score']:.3f}")
                    print(f"     {r['kural_tamil']}")
                    print(f"     {r['explanation'][:80]}â€¦")

    # â”€â”€ Save results â”€â”€
    out_file = APP_DIR.parent / "evaluation_results.json"
    with open(out_file, "w", encoding="utf-8") as f:
        json.dump({"metrics": metrics, "results": all_results}, f, ensure_ascii=False, indent=2)
    log.info(f"Detailed results saved â†’ {out_file}")

# â”€â”€ Run in Colab â”€â”€
main(image_dir=None)      # uncomment and run if you want image evaluation too